/******************************************************************************
 *
 * 	msm_irqbalance.c
 *
 * GENERAL DESCRIPTION
 *	IRQ Balancing for MSM SoC

 Copyright (c) 2014 Qualcomm Technologies, Inc.  All Rights Reserved.
 Qualcomm Technologies Proprietary and Confidential.
 ******************************************************************************/
#include <stdint.h>
#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <unistd.h>
#include <errno.h>
#include <fcntl.h>
#include <time.h>
#include <sys/capability.h>
#include <sys/prctl.h>
#include <poll.h>
#include <cutils/properties.h>
#include <private/android_filesystem_config.h>
#include "msm_irqbalance.h"

static char const *VERSION_STR = "1.3";

static char const *GIC_STR = "GIC";
static char const *PROC_STAT_PATH = "/proc/stat";
static char const *PROC_INTERRUPTS_PATH = "/proc/interrupts";
static char const *PROC_IRQ_AFFINITY_PATH = "/proc/irq/%d/smp_affinity";
static char const *PROC_IRQ_AFFINITY_PATH_2 = "/proc/irq/%d/smp_affinity_list";
static char const *SYS_DEF_TIMER_PATH = "/sys/devices/system/cpu/cpu0/rq-stats/def_timer_ms";

static uint32_t const SCRATCH_BUF_LEN = 1024;

static uint32_t const MAX_CPUS_POSSIBLE = 1024;

static char const *DEBUG_LOG_LEVEL_PROP = "persist.msmirqbalance.debug";
static uint32_t debug_enabled = false;

static uint32_t max_cpus;

#define MAX_NUM_INTERRUPTS 200

static char const *CPU_NAME_STR = "CPU%d";
static int32_t const SLOT_AVAILABLE = -1;

/* Knobs */
/* List of interrupts that we should ignore (not try to balance) */
static uint32_t const IRQ_IGNORE_LIST_DEF[] = {20, 39, 200, 203};
#define MAX_IGNORE_LIST_LEN 20

/* Decay factor for calculating interrupt activity */
static double const DEF_DECAY_FACTOR = 75.0;

/* Rate at which to run the algorithm */
static double const DEF_RATE_HZ = 0.2;

/* The difference (delta) in total IRQ count in last run between most active
 * CPU and least active CPU must be greater
 * than irq_count (most active cpu) * BALANCING_FACTOR for balancing to occur.
 */
static double const DEF_BALANCING_FACTOR = 0.1;

/* How many algorithm iterations to wait before allowing an IRQ to be moved again */
static uint32_t NUM_ITERATIONS_DEADBAND = 2;

/* Knobs end */

/*
 * irq_no	- Interrupt number (SLOT_AVAILABLE) indicates this slot is not used
 * ignore	- This interrupt is ignored (see IRQ_IGNORE_LIST above)
 * count	- Number of interrupts generated by this IRQ
 * prev_count	- Number of interrupts from previous run
 * delta_ps_count - Simply (count - prev_count) (per sec)
 * dc_ps_decay	- Decaying average of the delta count (per sec)
 */
struct interrupt {
	int32_t irq_no;
	bool ignore;
	uint64_t count;
	uint64_t prev_count;
	double delta_ps_count;
	double dc_ps_decay;
};

/*
 * ints		  - List of interrupts (gets sorted by "count")
 * irq_time 	  - Total time this CPU has spent in IRQ since last run
 * irq_time_prev  - Total time this CPU has spent in IRQ in previous run
 * irq_time_delta - Simply tot_irq_time - tot_irq_time_prev
 * irq_time_norm  - Normalized value of tot_irq_time
 * tot_num_irq - Number of IRQ serviced since boot
 * tot_num_irq_prev - Number of IRQ serviced from previous run
 * n_irq_ps_delta - Number of IRQs served per second (calculated since last run)
 * n_irq_ps_decay - Decaying average of above n_irq_ps_delta
 * prio           - priority of CPU for IRQ balancing. 0 means no IRQs should be
 * 		    scheduled on this cpu (banned cpu).
 */

struct cpu_info {
	struct interrupt ints[MAX_NUM_INTERRUPTS];
	uint32_t irq_time;
	uint32_t irq_time_prev;
	uint32_t irq_time_delta;
	double   irq_time_norm;
	uint64_t tot_num_irq;
	uint64_t tot_num_irq_prev;
	uint64_t n_irq_ps_delta;
	uint64_t n_irq_ps_decay;
	uint32_t prio;
};

static struct cpu_info *cpu_data;
/*
 * List of active CPUs
 * Value of SLOT_AVAILABLE indicates end of list.
 */

static uint32_t *cpu_active_list;

/*
 * List of all interrupts in the system that are handled
 * irq_no		- Interrupt number (SLOT_AVAILABLE) indicates this slot is not used
 * last_moved_it 	- Indicates at which iteration the IRQ was last moved
*/
struct irq_info {
	int irq_no;
	uint64_t last_moved_it;
};

static struct irq_info irq_list[MAX_NUM_INTERRUPTS];

/*
 * rate_hz  - Rate at which to run the algorithm
 * decay_factor - The decay factor
 * balancing_factor - The balancing factor
 * cpu_prio - List of priorities for each CPU. Priority of 0 means
 *            do NOT schedule interrupts on this CPU. Larger number the
 *            higher the priority.
 * ignored_irqs - List of ignored irqs
 * no_ignored_irqs - Number of ignored irqs
 * cfg_file - Name of configuration file
 */

struct cmdline {
	double rate_hz;
	double decay_factor;
	double balancing_factor;
	uint32_t *cpu_prio;
	uint32_t ignored_irqs[MAX_IGNORE_LIST_LEN];
	uint32_t no_ignored_irqs;
	char *cfg_file;
};

static char *scratch_buffer;
static FILE *stat_fp;
static FILE *ints_fp;
static int32_t def_sleep_fd;
static bool keep_going = true;
static bool restart = false;

static void sig_handler(int32_t signal)
{
	if (signal == SIGHUP) {
		keep_going = false;
		restart = true;
	} else if (signal == SIGTERM) {
		keep_going = false;
	}
}

/*
 * Check whether an IRQ should be ignored
 */
static bool ignore_irq(uint32_t irq_no, struct cmdline const *args)
{
	uint32_t i;

	for (i = 0; i < args->no_ignored_irqs; ++i) {
		if (args->ignored_irqs[i] == irq_no)
			return true;
	}
	return false;
}

static int open_proc_files(void)
{
	int32_t ret = 0;

	stat_fp = fopen(PROC_STAT_PATH, "r");
	if (!stat_fp) {
		error("Unable to open %s\n", PROC_STAT_PATH);
		ret = errno;
	}

	ints_fp = fopen(PROC_INTERRUPTS_PATH, "r");
	if (!ints_fp) {
		error("Unable to open %s\n", PROC_STAT_PATH);
		ret = errno;
	}

	def_sleep_fd = open(SYS_DEF_TIMER_PATH, O_RDONLY);
	if (!def_sleep_fd) {
		error("Unable to open %s\n", SYS_DEF_TIMER_PATH);
		ret = errno;
	}
	return ret;
}

static void close_proc_files(void)
{
	if (stat_fp)
		fclose(stat_fp);
	if (ints_fp)
		fclose(ints_fp);
	if (def_sleep_fd >= 0)
		close(def_sleep_fd);
}

static int32_t get_smp_affinity(uint32_t *cpu_mask, uint32_t int_num)
{
	int32_t ret = 0;
	int32_t n = snprintf(scratch_buffer, SCRATCH_BUF_LEN, PROC_IRQ_AFFINITY_PATH, int_num);

	if (n < 0 || n >= (int32_t) SCRATCH_BUF_LEN) {
		error("%s: Out of memory, n = %d\n", __func__, n);
		ret = -ENOMEM;
	} else {
		FILE *fp = fopen(scratch_buffer, "r");

		if (fp) {
			n = fscanf(fp, "%x", cpu_mask);
			if (n != 1)
				ret = -EINVAL;
			fclose(fp);
		} else {
			error("%s: Unable to open %s\n", __func__, scratch_buffer);
			ret = -EINVAL;
		}
	}

	return ret;
}

static int32_t get_smp_affinity_list(char *aff_list, uint32_t aff_list_len, uint32_t int_num)
{
	int32_t ret = 0;
	int32_t n = snprintf(scratch_buffer, SCRATCH_BUF_LEN, PROC_IRQ_AFFINITY_PATH_2, int_num);

	if (n < 0 || n >= (int32_t) SCRATCH_BUF_LEN) {
		error("%s: Out of memory, n = %d\n", __func__, n);
		ret = -ENOMEM;
	} else {
		FILE *fp = fopen(scratch_buffer, "r");

		if (fp) {
			char *ptr = fgets(aff_list, aff_list_len, fp);
			if (ptr == NULL)
				ret = -EINVAL;
			fclose(fp);
		} else {
			error("%s: Unable to open %s\n", __func__, scratch_buffer);
			ret = -EINVAL;
		}
	}

	return ret;
}

static int32_t __set_smp_affinity(char const *path, uint32_t int_num, uint32_t affinity)
{
	int32_t ret = 0;
	int32_t n;

	n = snprintf(scratch_buffer, SCRATCH_BUF_LEN, path, int_num);
	if (n < 0 || n >= (int32_t) SCRATCH_BUF_LEN) {
		error("%s: Out of memory, n = %d\n", __func__, n);
		ret = -ENOMEM;
	} else {
		FILE *fp;

		fp = fopen(scratch_buffer, "w");
		if (fp) {
			n = snprintf(scratch_buffer, SCRATCH_BUF_LEN, "%u", affinity);
			if (n < 0 || n >= (int32_t) SCRATCH_BUF_LEN) {
				error("%s: Out of memory, n = %d\n", __func__, n);
				ret = -ENOMEM;
			} else {
				n = fwrite(scratch_buffer, strlen(scratch_buffer), 1, fp);
				if (n != 1)
					ret = -EINVAL;
			}
			fclose(fp);
		} else {
			error("%s: Unable to open %s\n", __func__, scratch_buffer);
			ret = -EINVAL;
		}
	}
	return ret;
}

static int32_t set_smp_affinity(uint32_t cpu_no, uint32_t int_num)
{
	int32_t ret = 0;
	uint32_t affinity;
	uint32_t new_affinity;

	affinity = 1 << cpu_no;
	ret = __set_smp_affinity(PROC_IRQ_AFFINITY_PATH, int_num, affinity);

	if (!ret) {
		affinity = cpu_no;
		ret = __set_smp_affinity(PROC_IRQ_AFFINITY_PATH_2, int_num, affinity);
	}

	affinity = 1 << cpu_no;
	get_smp_affinity(&new_affinity, int_num);
	if (new_affinity != affinity)
		debug("Unable to set affinity for IRQ%d. Affinity value: 0x%x\n", int_num, new_affinity);

	return ret;
}

static uint32_t deferred_sleep(uint32_t sleep_ms)
{
	int32_t n;
	int32_t ret = 0;
	int32_t time_ms;

	n = snprintf(scratch_buffer, SCRATCH_BUF_LEN, "%u\n", sleep_ms);
	if (n < 0 || n >= (int32_t) SCRATCH_BUF_LEN) {
		error("%s: Out of memory, n = %d\n", __func__, n);
		ret = -ENOMEM;
	} else {
		FILE *fp = fopen(SYS_DEF_TIMER_PATH, "w");

		if (!fp) {
			error("%s: Unable to open %s\n", __func__, SYS_DEF_TIMER_PATH);
			ret = -EIO;
		} else {
			n = fwrite(scratch_buffer, strlen(scratch_buffer), 1, fp);
			if (n != 1) {
				error("%s: Error writing to %s\n", __func__, SYS_DEF_TIMER_PATH);
				ret = -EINVAL;
			}
			fclose(fp);
		}
	}

	if (!ret) {
		struct pollfd fds;
		int32_t err;

		fds.fd = def_sleep_fd;
		fds.events = POLLERR|POLLPRI;
		fds.revents = 0;

		err = poll(&fds, 1, -1);
		if (err > 0) {
			ret = 0;
		} else {
			error("Error waiting for fd: %d\n", err);
			ret = err;
		}
		if (!ret) {
			ret = read(def_sleep_fd, scratch_buffer, SCRATCH_BUF_LEN - 1);
			if (ret != -1) {
				lseek(def_sleep_fd, 0, SEEK_SET);
				time_ms = atoi(scratch_buffer);
				ret = time_ms;
			} else {
				error("%s: Error reading sleep time\n", __func__);
			}
		}

	}
	return ret;
}

static uint32_t read_interrupt_activity_header(void)
{
	char *res;
	uint32_t active_cpus = 0;
	uint32_t i;
	uint32_t cpu_id;

	/* Get header with CPU numbers */
	res = fgets(scratch_buffer, SCRATCH_BUF_LEN, ints_fp);
	if (res) {
		char *cpu_tok;
		char *cpu_tok_saveptr;
		int32_t n;

		cpu_tok = strtok_r(scratch_buffer, " ", &cpu_tok_saveptr);
		while (cpu_tok) {
			n = sscanf(cpu_tok, CPU_NAME_STR, &cpu_id);
			if (n == 1 && cpu_id < max_cpus) {
				cpu_active_list[active_cpus] = cpu_id;
				++active_cpus;
			} else {
				if (cpu_id >= max_cpus)
					error("%s: Found unsupported CPU ID: %d\n", __func__, cpu_id);
			}
			cpu_tok = strtok_r(NULL, " ", &cpu_tok_saveptr);
		}
	}
	return active_cpus;
}

static double calculate_decay(double new_value, double current,
				struct cmdline const *args)
{
	double decay_factor_scaled = args->decay_factor * args->rate_hz;
	double updated = (new_value / decay_factor_scaled +
			(decay_factor_scaled - 1.0) *
			current / decay_factor_scaled);
	return updated;
}

static void parse_one_interrupt(uint64_t iteration, char *tok_saveptr, int32_t irq_no, uint32_t num_active_cpus, struct cmdline const *args)
{
	uint32_t i;

	for (i = 0; i < num_active_cpus; ++i) {
		uint32_t j;
		uint64_t irq_count;
		int32_t n;

		uint32_t curr_cpu = cpu_active_list[i];
		char *tok = strtok_r(NULL, " ", &tok_saveptr);

		if (!tok)
			return;

		n = sscanf(tok, "%llu", &irq_count);

		if (n != 1)
			continue;

		/* Find slot used or new slot if interrupt has not
		 * been registered before
		 */
		j = 0;
		while (cpu_data[curr_cpu].ints[j].irq_no != SLOT_AVAILABLE &&
		       cpu_data[curr_cpu].ints[j].irq_no != irq_no)
			++j;

		if (cpu_data[curr_cpu].ints[j].irq_no == irq_no) {
			cpu_data[curr_cpu].ints[j].prev_count = cpu_data[curr_cpu].ints[j].count;
		} else {
			cpu_data[curr_cpu].ints[j].irq_no = irq_no;
			cpu_data[curr_cpu].ints[j].ignore = ignore_irq(irq_no, args);
		}

		if (!cpu_data[curr_cpu].ints[j].ignore) {
			uint64_t delta_count;
			double delta_count_per_sec;
			double dcd_prev = cpu_data[curr_cpu].ints[j].dc_ps_decay;
			cpu_data[curr_cpu].tot_num_irq += irq_count;
			cpu_data[curr_cpu].ints[j].count = irq_count;
			delta_count = irq_count - cpu_data[curr_cpu].ints[j].prev_count;
			delta_count_per_sec = ((double) delta_count) * args->rate_hz;
			cpu_data[curr_cpu].ints[j].delta_ps_count = delta_count_per_sec;
			if (iteration)
				cpu_data[curr_cpu].ints[j].dc_ps_decay = calculate_decay(delta_count_per_sec, dcd_prev, args);
		}
	}
}

static void add_irq_to_list(int32_t irq_no, bool silent)
{
	uint32_t i;

	for(i = 0; i < MAX_NUM_INTERRUPTS; ++i) {
		if (irq_list[i].irq_no == irq_no) {
			break;
		} else if (irq_list[i].irq_no == SLOT_AVAILABLE) {
			irq_list[i].irq_no = irq_no;
			irq_list[i].last_moved_it = 0;
			if (!silent)
				info("Discovered a new IRQ: %d\n", irq_no);
			break;
		}
	}
	if (i == MAX_NUM_INTERRUPTS)
		error("Too many interrupts!\n");
}

static int32_t read_interrupt_activity(uint64_t iteration, uint32_t *num_active_cpus, struct cmdline const *args)
{
	char *res;
	int32_t ret = 0;

	int32_t irq_no;
	uint32_t i, j;

	for(i = 0; i < max_cpus; ++i) {
		cpu_active_list[i] = SLOT_AVAILABLE;
		cpu_data[i].tot_num_irq_prev = cpu_data[i].tot_num_irq;
		cpu_data[i].tot_num_irq = 0;
	}

	*num_active_cpus = read_interrupt_activity_header();

	res = fgets(scratch_buffer, SCRATCH_BUF_LEN, ints_fp);
	while (res) {
		char *tok;
		char *tok_saveptr;
		int n;
		bool is_gic_irq;

		is_gic_irq = (strstr(scratch_buffer, GIC_STR) != NULL);

		tok = strtok_r(scratch_buffer, " ", &tok_saveptr);
		if (tok) {
			/* Silently ignoring interrupts that does not start with a number */
			n = sscanf(tok, "%d:", &irq_no);
			if (n == 1) {
				if (is_gic_irq) {
					add_irq_to_list(irq_no, iteration == 0);
					parse_one_interrupt(iteration, tok_saveptr, irq_no, *num_active_cpus, args);
				}
			}
		} else {
			error("Ignored %s\n", scratch_buffer);
		}
		res = fgets(scratch_buffer, SCRATCH_BUF_LEN, ints_fp);
	}

	for (i = 0; i < *num_active_cpus; ++i) {
		uint32_t curr_cpu = cpu_active_list[i];

		if (cpu_data[curr_cpu].tot_num_irq_prev) {
			uint64_t n_irq_ps_delta;
			uint64_t n_irq_ps_decay;
			uint64_t n_irq_ps_decay_prev = cpu_data[curr_cpu].n_irq_ps_decay;

			n_irq_ps_delta  = ((double)(cpu_data[curr_cpu].tot_num_irq
					   - cpu_data[curr_cpu].tot_num_irq_prev))
					   * args->rate_hz;
			cpu_data[curr_cpu].n_irq_ps_delta = n_irq_ps_delta;
			n_irq_ps_decay = calculate_decay(n_irq_ps_delta, n_irq_ps_decay_prev, args);
			cpu_data[curr_cpu].n_irq_ps_decay = n_irq_ps_decay;
		}
	}

	rewind(ints_fp);
	return ret;
}

static int32_t read_interrupt_time(void)
{
	char *res;
	int32_t ret = 0;
	int32_t irq_no;
	uint32_t i, j;
	uint32_t no_found = 0;

	res = fgets(scratch_buffer, SCRATCH_BUF_LEN, stat_fp);
	if (res) {
		int n;
		uint32_t user, nice, system, idle, iowait, irq, softirq, steal, guest,  guest_nice;
		uint32_t tot_time;
		uint32_t cpu_id;

		n = sscanf(scratch_buffer, "cpu %u %u %u %u %u %u %u %u %u %u",
			   &user, &nice, &system, &idle, &iowait, &irq, &softirq, &steal, &guest,  &guest_nice);
		if (n > 5) {
			for (i = 0; i < max_cpus; ++i) {
				res = fgets(scratch_buffer, SCRATCH_BUF_LEN, stat_fp);
				if (res) {
					n = sscanf(scratch_buffer, "cpu%u %u %u %u %u %u %u %u %u %u %u",
						   &cpu_id, &user, &nice, &system, &idle, &iowait, &irq, &softirq, &steal, &guest,  &guest_nice);
					if (n > 6) {
						if (cpu_id >= max_cpus) {
							error("%s: Found unsupported CPU ID %u\n", __func__, cpu_id);
							continue;
						}
						tot_time = user + nice + system + idle + iowait + irq + softirq + steal + guest + guest_nice;
						cpu_data[cpu_id].irq_time_prev = cpu_data[cpu_id].irq_time;
						cpu_data[cpu_id].irq_time_delta = irq - cpu_data[cpu_id].irq_time_prev;
						cpu_data[cpu_id].irq_time = irq;
						if (tot_time == 0)
							cpu_data[cpu_id].irq_time_norm = 0.0;
						else
							cpu_data[cpu_id].irq_time_norm = (double) irq / (double) tot_time;

						++no_found;
					} else {
						//error("%s: Ignored %s\n", __func__, scratch_buffer);
					}
				} else {
					ret = errno;
					break;
				}
			}
		}
	} else {
		error("%s: Failed reading %s\n", __func__, PROC_STAT_PATH);
		ret = errno;
	}
	if (!no_found) {
		error("%s: Error reading %s\n", __func__, PROC_STAT_PATH);
		ret = -EIO;
	}

	rewind(stat_fp);
	return ret;
}

static int32_t get_interrupt_activity(uint64_t iteration, uint32_t *num_active_cpus, struct cmdline const *args)
{
	int32_t ret = 0;

	ret = read_interrupt_activity(iteration, num_active_cpus, args);
	if (ret)
		return ret;
	ret = read_interrupt_time();

	return ret;
}

static struct irq_info *find_irq_info(int32_t irq_no)
{
	uint32_t i;

	for(i = 0; i < MAX_NUM_INTERRUPTS; ++i) {
		if (irq_list[i].irq_no == irq_no)
			return &irq_list[i];
	}
	return NULL;
}

static bool check_deadband(int32_t irq_no, uint64_t iteration)
{
	struct irq_info *irq_info = find_irq_info(irq_no);
	uint64_t delta_iteration = ~0;

	if (irq_info)
		delta_iteration = iteration - irq_info->last_moved_it;

	return delta_iteration >= NUM_ITERATIONS_DEADBAND;
}

static int32_t cpu_activity_compare(const void *elem1, const void *elem2)
{
	int32_t e1 = (int32_t) *((int32_t *)elem1);
	int32_t e2 = (int32_t) *((int32_t *)elem2);
	uint64_t workload1;
	uint64_t workload2;

	if (e1 == SLOT_AVAILABLE && e2 == SLOT_AVAILABLE)
		return 0;
	if (e1 == SLOT_AVAILABLE)
		return 1;
	if (e2 == SLOT_AVAILABLE)
		return -1;

	workload1 = cpu_data[e1].n_irq_ps_decay;
	workload2 = cpu_data[e2].n_irq_ps_decay;

	if (workload1 > workload2)
		return -1;
	if (workload2 > workload1)
		return 1;

	return 0;
}

static int32_t cpu_prio_compare(const void *elem1, const void *elem2)
{
	int32_t e1 = (int32_t) *((int32_t *)elem1);
	int32_t e2 = (int32_t) *((int32_t *)elem2);
	uint32_t p1;
	uint32_t p2;

	if (e1 == SLOT_AVAILABLE && e2 == SLOT_AVAILABLE)
		return 0;
	if (e1 == SLOT_AVAILABLE)
		return 1;
	if (e2 == SLOT_AVAILABLE)
		return -1;

	p1 = cpu_data[e1].prio;
	p2 = cpu_data[e2].prio;

	if (p1 > p2)
		return -1;
	if (p2 > p1)
		return 1;

	return 0;
}


static int32_t cpu_interrupt_compare(const void *elem1, const void *elem2)
{
	double delta1;
	double delta2;
	struct interrupt *e1 = (struct interrupt *) elem1;
	struct interrupt *e2 = (struct interrupt *) elem2;

	if (e1->irq_no == SLOT_AVAILABLE && e2->irq_no == SLOT_AVAILABLE)
		return 0;
	if (e1->irq_no == SLOT_AVAILABLE)
		return 1;
	if (e2->irq_no == SLOT_AVAILABLE)
		return -1;

	delta1 = e1->delta_ps_count;
	delta2 = e2->delta_ps_count;

	if (delta1 > delta2)
		return -1;
	if (delta2 > delta1)
		return 1;

	return 0;
}

/*
 * Find the interrupt that is closest in count to specified value
 */
static int32_t find_irq_w_close_count(struct interrupt *ints, uint64_t count, uint64_t iteration)
{
	int32_t irq_idx = 0;
	bool found = false;
	int32_t saved_idx;

	while (irq_idx < MAX_NUM_INTERRUPTS && ints[irq_idx].irq_no != SLOT_AVAILABLE
	       && ints[irq_idx].delta_ps_count > (double) count) {
		++irq_idx;
	}

	if (irq_idx == MAX_NUM_INTERRUPTS)
		--irq_idx;

	if (irq_idx > 0) {
		uint64_t count_above = ints[irq_idx - 1].delta_ps_count;
		uint64_t count_below = ints[irq_idx].delta_ps_count;

		uint64_t dist_above = count_above - count;
		uint64_t dist_below = count - count_below;

		if (dist_above < dist_below)
			--irq_idx;
	}

	saved_idx = irq_idx;

	/* Search up to find an IRQ that can be moved */
	while (irq_idx < MAX_NUM_INTERRUPTS && ints[irq_idx].irq_no != SLOT_AVAILABLE
	       && ints[irq_idx].delta_ps_count > 0.0) {

		if(check_deadband(ints[irq_idx].irq_no, iteration)) {
			found = true;
			break;
		}
		++irq_idx;
	}
	if (!found) {
		/* Search down to find an IRQ that can be moved */
		irq_idx = saved_idx;
		while (irq_idx >= 0 && ints[irq_idx].irq_no != SLOT_AVAILABLE
		       && ints[irq_idx].delta_ps_count > 0.0) {

			if(check_deadband(ints[irq_idx].irq_no, iteration)) {
				found = true;
				break;
			}
			--irq_idx;
		}
	}
	if (!found)
		irq_idx = -1;

	return irq_idx;
}

static void dump_irq(struct interrupt *irq)
{
	info("IRQ: %u\n", irq->irq_no);
	info("Ignore: %u\n", irq->ignore);
	info("count: %llu\n", irq->count);
	info("prev_count: %llu\n", irq->prev_count);
	info("delta_ps_count: %.1f\n", irq->delta_ps_count);
	info("dc_ps_decay: %.1f\n", irq->dc_ps_decay);

}

static void move_interrupt_info(uint32_t cpu_dest, struct interrupt *irq)
{
	uint32_t irq_idx = 0;
	struct interrupt *ints = cpu_data[cpu_dest].ints;
	struct interrupt *dst_irq;

	while (irq_idx < MAX_NUM_INTERRUPTS &&
	       ints[irq_idx].irq_no != irq->irq_no &&
	       ints[irq_idx].irq_no != SLOT_AVAILABLE)
		++irq_idx;

	if (irq_idx < MAX_NUM_INTERRUPTS) {
		dst_irq = &ints[irq_idx];

		dst_irq->irq_no = irq->irq_no;
		dst_irq->count = dst_irq->prev_count;
		dst_irq->dc_ps_decay = 0.0;
	}
}

static int32_t make_balancing_decision(uint32_t num_act_cpus, uint64_t iteration,
					struct cmdline const *args)
{
	uint32_t ret = 0;
	uint32_t do_balance = 0;
	uint32_t curr_mac = 0;
	uint32_t lac_idx = num_act_cpus - 1;
	uint32_t lac = cpu_active_list[lac_idx]; /* Least active cpu */

	/* Find the least active CPU that is not banned */
	while (cpu_data[lac].prio == 0 && lac_idx > 1) {
		--lac_idx;
		lac = cpu_active_list[lac_idx];
	}

	/* Nothing to do if all the CPUs are banned */
	if (cpu_data[lac].prio == 0)
		return ret;

	while (!do_balance && curr_mac < lac_idx) {
		uint32_t mac = cpu_active_list[curr_mac];
		int32_t irq_idx;
		double delta_ps_count;
		uint64_t dc;
		uint64_t delta_mac_irq_count_decay = cpu_data[mac].n_irq_ps_decay;
		uint64_t delta_irq_count_decay = (delta_mac_irq_count_decay - cpu_data[lac].n_irq_ps_decay);
		struct interrupt *irq;

		/* Looking at the decaying delta irq count between most active
		 * cpu and least active CPU, find the interrupt that matches closest
		 * to half of the delta.
		 */
		irq_idx = find_irq_w_close_count(cpu_data[mac].ints, delta_irq_count_decay / 2, iteration);
		if (irq_idx >= 0) {
			irq = &cpu_data[mac].ints[irq_idx];

			delta_ps_count = irq->delta_ps_count;

			/*
			 * Only balance if there is more than 1 active interrupt on
			 * most active cpu. (Interrupt 1 is the second most active
			 * IRQ)
			 */
			if (cpu_data[mac].ints[1].delta_ps_count > 0.0) {
				do_balance = (delta_ps_count > 0.0 &&
					      delta_irq_count_decay > (delta_mac_irq_count_decay * args->balancing_factor));
			}

			if (do_balance) {
				struct irq_info *irq_info = find_irq_info(irq->irq_no);

				if (irq_info) {
					info("Decided to move IRQ%d from CPU%d to CPU%d\n", irq->irq_no, mac, lac);
					ret = set_smp_affinity(lac, irq->irq_no);

					if (!ret)
						move_interrupt_info(lac, irq);
					else
						error("Unable to set SMP affinity\n");
					irq_info->last_moved_it = iteration;
				} else {
					error("IRQ not found in internal structure. Trying to find IRQ%u\n", irq->irq_no);
					do_balance = 0;
				}

			}
		}
		++curr_mac;
	}

	return ret;
}

static void print_active_irqs(uint32_t curr_cpu, char *buff, uint32_t buf_len)
{
	uint32_t j;
	uint32_t curr_len = 0;
	int32_t len;

	len = snprintf(buff, buf_len, "Active: [");
	if (len < 0 || len >= (int32_t) buf_len) {
		error("Unable to print irqs\n");
		return;
	}
	curr_len = len;

	for (j = 0; j < MAX_NUM_INTERRUPTS; ++j) {
		int32_t irq_no = cpu_data[curr_cpu].ints[j].irq_no;
		double delta_ps = cpu_data[curr_cpu].ints[j].delta_ps_count;
		double dc_ps_decay = cpu_data[curr_cpu].ints[j].dc_ps_decay;

		if (delta_ps > 0.0) {
			if (curr_len >= buf_len) {
				error("Unable to print irqs\n");
				break;
			}

			len = snprintf(&buff[curr_len], buf_len - curr_len, "IRQ%u %.1f [%.1f] ", irq_no, dc_ps_decay, delta_ps);
			if (len < 0 || len >= (int32_t) (buf_len - curr_len)) {
				error("Unable to print irqs\n");
				break;
			} else {
				curr_len += len;
			}
		}
	}
	if (curr_len < (buf_len - 1)) {
		buff[curr_len++] = ']';
		buff[curr_len] = '\0';
	}
}

static uint32_t get_num_avail_cpus(uint32_t num_act_cpus)
{
	uint32_t i;
	uint32_t num_avail_cpus = 0;

	for (i = 0; i < num_act_cpus; ++i) {
		int32_t curr_cpu = cpu_active_list[i];
		if (curr_cpu < 0)
			break;
		if (cpu_data[curr_cpu].prio > 0)
			++num_avail_cpus;
		else
			break;
	}
	return num_avail_cpus;
}

/*
 * When first started the daemon uses this function to move ALL IRQs
 * away from any banned CPUs
 */
static uint32_t move_all_irqs_from_banned_cpus(uint32_t num_act_cpus, uint64_t iteration, struct cmdline const *args)
{
	uint32_t j;
	uint32_t num_irq_moved = 0;
	uint32_t num_avail_cpus = 0;
	uint32_t last_dest_cpu_idx = 0;
	uint32_t last_dest_cpu = 0;

	num_avail_cpus = get_num_avail_cpus(num_act_cpus);

	/* No banned CPUs */
	if (num_avail_cpus == num_act_cpus)
		return 0;

	last_dest_cpu = cpu_active_list[last_dest_cpu_idx];

	for (j = 0; j < MAX_NUM_INTERRUPTS; ++j) {
		int32_t irq_no = irq_list[j].irq_no;

		if (irq_no == SLOT_AVAILABLE)
			break;

		if (!ignore_irq(irq_no, args)) {
			int32_t ret = set_smp_affinity(last_dest_cpu, irq_no);
			struct irq_info *irq_info = find_irq_info(irq_no);

			if (ret)
				error("Unable to set SMP affinity\n");

			/* Rotate which CPU to migrate to */
			++last_dest_cpu_idx;
			if (last_dest_cpu_idx >= max_cpus)
				last_dest_cpu_idx = 0;

			last_dest_cpu = cpu_active_list[last_dest_cpu_idx];

			if (cpu_data[last_dest_cpu].prio == 0)
				last_dest_cpu_idx = 0;

			last_dest_cpu = cpu_active_list[last_dest_cpu_idx];

			++num_irq_moved;

			if (irq_info)
				irq_info->last_moved_it = iteration;
		}
	}
	return num_irq_moved;
}


static uint32_t move_irq_from_banned_cpus(uint32_t num_act_cpus, uint64_t iteration, struct cmdline const *args)
{
	int32_t i;
	uint32_t num_irq_moved = 0;
	uint32_t num_avail_cpus = 0;
	uint32_t last_dest_cpu_idx = 0;
	uint32_t last_dest_cpu = 0;
	uint32_t aff;

	num_avail_cpus = get_num_avail_cpus(num_act_cpus);

	/* No banned CPUs */
	if (num_avail_cpus == num_act_cpus)
		return 0;

	last_dest_cpu = cpu_active_list[last_dest_cpu_idx];

	for (i = num_act_cpus - 1; i >= 0; --i) {
		int32_t curr_cpu = cpu_active_list[i];
		if (curr_cpu < 0) {
			break;
		} else {
			uint32_t prio = cpu_data[curr_cpu].prio;
			if (prio == 0) {
				uint32_t j;

				for (j = 0; j < MAX_NUM_INTERRUPTS; ++j) {
					struct interrupt *irq = &cpu_data[curr_cpu].ints[j];
					int32_t irq_no = irq->irq_no;
					double delta_ps = irq->delta_ps_count;
					uint32_t curr_cpu_prio = cpu_data[curr_cpu].prio;
					uint32_t last_dest_cpu_prio = cpu_data[last_dest_cpu].prio;
					int ret;

					if (delta_ps > 0.0) {
						if (!ignore_irq(irq_no, args) && check_deadband(irq_no, iteration)) {
							info("Decided to move IRQ%d from CPU%d [P:%u] to CPU%d [P:%u] (banned)\n",
							      irq_no, curr_cpu, curr_cpu_prio, last_dest_cpu, last_dest_cpu_prio);
							ret = set_smp_affinity(last_dest_cpu, irq_no);

							if (!ret)
								move_interrupt_info(last_dest_cpu, irq);
							else
								error("Unable to set SMP affinity\n");

							/* Rotate which CPU to migrate to */
							++last_dest_cpu_idx;
							if (last_dest_cpu_idx >= max_cpus)
								last_dest_cpu_idx = 0;

							last_dest_cpu = cpu_active_list[last_dest_cpu_idx];

							if (cpu_data[last_dest_cpu].prio == 0)
								last_dest_cpu_idx = 0;

							last_dest_cpu = cpu_active_list[last_dest_cpu_idx];

							++num_irq_moved;
						}
					} else {
						break;
					}
				}
			}

		}
	}
	return num_irq_moved;
}

static void dump_irq_data(uint32_t num_act_cpus)
{
	uint32_t i;

	for (i = 0; i < num_act_cpus; ++i) {
		int32_t curr_cpu = cpu_active_list[i];
		if (curr_cpu < 0) {
			break;
		} else {
			double irq_time_norm = cpu_data[curr_cpu].irq_time_norm;
			uint32_t irq_time_delta = cpu_data[curr_cpu].irq_time_delta;
			uint32_t irq_time = cpu_data[curr_cpu].irq_time;
			uint64_t tot_num_irq = cpu_data[curr_cpu].tot_num_irq;
			uint64_t n_irq_ps_delta = cpu_data[curr_cpu].n_irq_ps_delta;
			uint64_t n_irq_ps_decay = cpu_data[curr_cpu].n_irq_ps_decay;
			int32_t irq_no = cpu_data[curr_cpu].ints[0].irq_no;
			uint32_t prio = cpu_data[curr_cpu].prio;

			if (debug_enabled)
				print_active_irqs(curr_cpu, scratch_buffer, SCRATCH_BUF_LEN);
			debug("CPU%01u [P:%u] Tot #: %10llu (PerSec: %6llu [%6llu]) Tot Time: %6u (Delta: %6u) Norm: %.6f %s\n",
					curr_cpu, prio, tot_num_irq, n_irq_ps_decay, n_irq_ps_delta,
					irq_time, irq_time_delta, irq_time_norm, scratch_buffer);
		}
	}
}

static int32_t balance_irq(uint32_t num_act_cpus, uint64_t iteration,
				struct cmdline const *args)
{
	uint32_t ret = 0;
	uint32_t i;
	uint32_t num_irq_moved;

	if (num_act_cpus < 2) {
		debug("Only 1 CPU. No work\n");
		return 0;
	}

	/* Sort for dumping */
	qsort(cpu_active_list, num_act_cpus, sizeof(cpu_active_list[0]), cpu_activity_compare);

	/* Find most active interrupt on each CPU */
	for (i = 0; i < num_act_cpus; ++i) {
		int32_t curr_cpu = cpu_active_list[i];

		if (curr_cpu < 0)
			break;

		qsort(cpu_data[curr_cpu].ints, MAX_NUM_INTERRUPTS, sizeof(cpu_data[curr_cpu].ints[0]), cpu_interrupt_compare);
	}

	dump_irq_data(num_act_cpus);

	/* First move IRQs off cores that are banned */
	if (iteration == 1) {
		/* First time just move all of the interrupts */
		qsort(cpu_active_list, num_act_cpus, sizeof(cpu_active_list[0]), cpu_prio_compare);
		num_irq_moved = move_all_irqs_from_banned_cpus(num_act_cpus, iteration, args);
	} else {
		qsort(cpu_active_list, num_act_cpus, sizeof(cpu_active_list[0]), cpu_prio_compare);
		num_irq_moved = move_irq_from_banned_cpus(num_act_cpus, iteration, args);
	}

	/* Then balance based on IRQ activity */
	/* Only balance if we didn't move any interrupts */
	if (num_irq_moved == 0) {
		qsort(cpu_active_list, num_act_cpus, sizeof(cpu_active_list[0]), cpu_activity_compare);
		ret = make_balancing_decision(num_act_cpus, iteration, args);
	}

	return ret;
}

static void init(struct cmdline const *args)
{
	uint32_t i,j;

	property_get(DEBUG_LOG_LEVEL_PROP, scratch_buffer, "false");

	if (strcmp(scratch_buffer, "true") == 0)
		debug_enabled = true;
	else
		debug_enabled = false;

	memset(cpu_data, 0, max_cpus * sizeof(*cpu_data));

	for(i = 0; i < max_cpus; ++i) {
		for (j = 0; j < MAX_NUM_INTERRUPTS; ++j) {
			cpu_data[i].ints[j].irq_no = SLOT_AVAILABLE;
		}
		cpu_data[i].prio = args->cpu_prio[i];
		cpu_active_list[i] = SLOT_AVAILABLE;
	}
	for (j = 0; j < MAX_NUM_INTERRUPTS; ++j)
		irq_list[j].irq_no = SLOT_AVAILABLE;

	info("msm-irq_balance (%s) initialized\n", VERSION_STR);
}

static void deinit(void)
{
	info("msm-irq_balance End\n");
}

static void dump_config(struct cmdline const *args);

static int run(struct cmdline const *args)
{
	int32_t ret = 0;
	uint32_t num_act_cpus;
	uint64_t iteration;
	uint32_t sleep_sec;

	sleep_sec = 1.0f / args->rate_hz;
start:
	keep_going = true;
	restart = false;
	iteration = 0;

	init(args);

	dump_config(args);

	ret = open_proc_files();

	if (!ret) {
		struct timeval now, time_last;
		double elapsed_ms;
		int32_t time_actually_slept_ms;

		gettimeofday(&now, NULL);
		time_last = now;

		/* Prime the statistics */
		get_interrupt_activity(iteration, &num_act_cpus, args);

		while (keep_going) {
			gettimeofday(&now, NULL);
			elapsed_ms = (now.tv_sec - time_last.tv_sec) * 1000.0 + (now.tv_usec - time_last.tv_usec) / 1000.0;
			time_last = now;
			time_actually_slept_ms = deferred_sleep(sleep_sec * 1000);

			if (time_actually_slept_ms < 0) {
				error("Failed to sleep for %u seconds\n", sleep_sec);
				break;
			}

			++iteration;
			debug("************************IRQ BALANCE iteration %llu [Time: %.1f (%.1f) sec]*********************\n", iteration, elapsed_ms / 1000.0, time_actually_slept_ms / 1000.0);
			ret = get_interrupt_activity(iteration, &num_act_cpus, args);
			if (ret) {
				error("Error getting interrupt activity: %d\n", ret);
				break;
			}
			ret = balance_irq(num_act_cpus, iteration, args);
			if (ret) {
				error("Error balancing IRQ: %d\n", ret);
				break;
			}
		}
	} else {
		error("Could not open files: %d\n", ret);
	}

	close_proc_files();

	deinit();

	if (restart) {
		info("Restarting...\n");
		goto start;
	}
	return ret;
}

static int parse_cpu_prio(char const *optarg, struct cmdline *cmdargs)
{
	uint32_t i = 0;

	char *cpu_tok;
	char *cpu_tok_saveptr;
	int32_t n;
	uint32_t prio;
	char *tmp_arg = strdup(optarg);

	if(!tmp_arg)
		return -ENOMEM;

	cpu_tok = strtok_r(tmp_arg, ",", &cpu_tok_saveptr);
	while (cpu_tok) {
		n = sscanf(cpu_tok, "%u", &prio);
		if (n == 1) {
			if (i < max_cpus) {
				cmdargs->cpu_prio[i] = prio;
				++i;
			} else {
				error("WARNING: Too many priorities specified.\n");
				break;
			}
		} else {
			error("%s: Error parsing cpu priority: %d\n", __func__, prio);
		}
		cpu_tok = strtok_r(NULL, ",", &cpu_tok_saveptr);
	}

	free(tmp_arg);
	return 0;
}

static int parse_ignored_irqs(char const *optarg, struct cmdline *cmdargs)
{
	char *tok;
	char *tok_saveptr;
	int32_t n;
	uint32_t irq_no;
	char *tmp_arg = strdup(optarg);

	if(!tmp_arg)
		return -ENOMEM;

	cmdargs->no_ignored_irqs = 0;

	tok = strtok_r(tmp_arg, ",", &tok_saveptr);
	while (tok) {
		n = sscanf(tok, "%u", &irq_no);
		if (n == 1) {
			if (cmdargs->no_ignored_irqs < MAX_IGNORE_LIST_LEN) {
				cmdargs->ignored_irqs[cmdargs->no_ignored_irqs] = irq_no;
				++cmdargs->no_ignored_irqs;
			} else {
				error("WARNING: Too many IRQs specified.\n");
				break;
			}
		} else {
			error("%s: Error parsing ignored IRQs: %d\n", __func__, irq_no);
		}
		tok = strtok_r(NULL, ",", &tok_saveptr);
	}

	free(tmp_arg);
	return 0;
}

/* You would want to keep below CFG_OPTIONS and CFG_OPTIONS_STR in sync */
enum CFG_OPTIONS {
	CO_RATE,
	CO_BALANCING_FACTOR,
	CO_DECAY_FACTOR,
	CO_PRIO,
	CO_IGNORED_IRQ,
	CO_CFG_FILE,
	CO_INVALID, /* Always last element */
};

/* You would want to keep CFG_OPTIONS and CFG_OPTIONS_STR in sync */
static char *CFG_OPTIONS_STR[] = {
	"RATE",
	"BALANCING_FACTOR",
	"DECAY_FACTOR",
	"PRIO",
	"IGNORED_IRQ",
	"CFG_FILE",
};

static int32_t set_option(enum CFG_OPTIONS opt, char const *value, struct cmdline *cmdargs)
{
	int32_t ret = 0;

	switch (opt) {
	case CO_RATE:
		    cmdargs->rate_hz = atof(value);
		    if (cmdargs->rate_hz < 0.001) {
			    error("Invalid rate specified: %f\n", cmdargs->rate_hz);
			    ret = -EINVAL;
		    }
		    break;
	case CO_PRIO:
		    ret = parse_cpu_prio(value, cmdargs);
		    break;
	case CO_DECAY_FACTOR:
		cmdargs->decay_factor = atof(value);
		if (cmdargs->decay_factor < 0.001) {
		    error("Invalid decay factor specified: %f\n", cmdargs->decay_factor);
		    ret = -EINVAL;
		}
		break;
	case CO_BALANCING_FACTOR:
		cmdargs->balancing_factor = atof(value);
		break;
	case CO_IGNORED_IRQ:
		    ret = parse_ignored_irqs(value, cmdargs);
		    break;
	case CO_CFG_FILE:
		    if (!cmdargs->cfg_file) {
			cmdargs->cfg_file = strdup(value);
			if (!cmdargs->cfg_file) {
				error("Unable to allocate memory for string\n");
				ret = -ENOMEM;
			}
		    }
		    break;
	default:
	    ret = -EINVAL;
	    break;
	}
	return ret;
}

static int32_t find_and_set_opt(char const *name, char const *value, struct cmdline *cmdargs)
{
	int32_t ret = -EINVAL;
	uint32_t i = 0;
	uint32_t len = sizeof(CFG_OPTIONS_STR) / sizeof(CFG_OPTIONS_STR[0]);
	enum CFG_OPTIONS opt;

	for (opt = 0; (uint32_t) opt < len; ++opt) {
		if (strcmp(name, CFG_OPTIONS_STR[opt]) == 0)
			break;
	}

	if ((uint32_t) opt < len)
		ret = set_option(opt, value, cmdargs);
	else
		error("Invalid option %s\n", name);

	return ret;
}

/**
 * Parse a configuration file containing name,value pairs like this:
 * RATE=0.2
 * BALANCING_FACTOR=0.1
 */
static int32_t parse_cfg_file(struct cmdline *cmdargs)
{
	int32_t ret = 0;
	FILE *f;

	f = fopen(cmdargs->cfg_file, "r");
	if (!f) {
		error("Unable to open %s\n", cmdargs->cfg_file);
		ret = errno;
	} else {
		char *ptr = fgets(scratch_buffer, SCRATCH_BUF_LEN, f);

		while (ptr) {
			char *name;
			char *value;
			char *tok_saveptr;

			name = strtok_r(ptr, "=", &tok_saveptr);
			if (!name) {
				ptr = fgets(scratch_buffer, SCRATCH_BUF_LEN, f);
				continue;
			}
			value = strtok_r(NULL, "=", &tok_saveptr);
			if (!value) {
				ptr = fgets(scratch_buffer, SCRATCH_BUF_LEN, f);
				continue;
			}

			ret = find_and_set_opt(name, value, cmdargs);
			if (ret)
				break;
			ptr = fgets(scratch_buffer, SCRATCH_BUF_LEN, f);
		}
		fclose(f);
	}
	if (ret)
		error("Error parsing configuration file %s\n", cmdargs->cfg_file);
	return ret;
}

static enum CFG_OPTIONS opt_to_enum(int32_t opt)
{
	enum CFG_OPTIONS cfgopt;

	switch (opt) {
	case 'r':
		cfgopt = CO_RATE;
		break;
	case 'p':
		cfgopt = CO_PRIO;
		break;
	case 'd':
		cfgopt = CO_DECAY_FACTOR;
		break;
	case 'b':
		cfgopt = CO_BALANCING_FACTOR;
		break;
	case 'i':
		cfgopt = CO_IGNORED_IRQ;
		break;
	case 'f':
		cfgopt = CO_CFG_FILE;
		break;
	default:
	    cfgopt = CO_INVALID;
	    break;
	}

	return cfgopt;
}

static int parse_cmdline(int argc, char *argv[], struct cmdline *cmdargs)
{
	int32_t ret = 0;
	int32_t opt;
	enum CFG_OPTIONS cfgopt;

	while (ret == 0 && (opt = getopt(argc, argv, "r:p:d:b:i:f:")) != -1) {
		cfgopt = opt_to_enum(opt);

		if (cfgopt == CO_INVALID) {
		    error("Invalid argument: %c\n", opt);
		    error("Usage: %s [-r hz] [-p cpu0_prio,cpu1_prio,cpuX_prio...] [-d decay_factor] [-b balancing factor] [-f cfg file name] \n", argv[0]);
		    ret = -EINVAL;
		    break;
		} else {
			ret = set_option(cfgopt, optarg, cmdargs);
		}
	}
	return ret;
}

#define BUFFER_SIZE 100

static void dump_config(struct cmdline const *args)
{
	uint32_t curr_len;
	int32_t len;
	uint32_t i;
	char buff[BUFFER_SIZE];

	info("Configuration\n");
	info("Rate: %.1f Hz\n", args->rate_hz);
	info("Decay Factor: %.1f\n", args->decay_factor);
	info("Balancing Factor: %.1f\n", args->balancing_factor);
	info("Debug Log: %s\n", debug_enabled ? "ON" : "OFF");
	info("Cfg file: %s\n", (args->cfg_file) ? args->cfg_file : "None");
	len = snprintf(buff, BUFFER_SIZE, "CPU PRIO: ");
	if (len < 0 || len >= BUFFER_SIZE) {
		error("Unable to construct config string: %d\n", len);
		return;
	}

	curr_len = len;
	for (i = 0; i < max_cpus; ++i) {
		if (curr_len >= BUFFER_SIZE) {
			error("Unable to construct config string: %d\n", curr_len);
			return;
		}

		len = snprintf(&buff[curr_len], BUFFER_SIZE - curr_len, "CPU%u: %u ", i, args->cpu_prio[i]);
		if (len < 0 || len >= (int32_t) (BUFFER_SIZE - curr_len)) {
			error("Unable to construct config string: %d\n", len);
			return;
		}
		curr_len += len;
	}

	info("%s\n", buff);

	len = snprintf(buff, BUFFER_SIZE, "Ignored IRQs: ");
	if (len < 0 || len >= BUFFER_SIZE) {
		error("Unable to construct config string: %d\n", len);
		return;
	}

	curr_len = len;
	for (i = 0; i < args->no_ignored_irqs; ++i) {
		if (curr_len >= BUFFER_SIZE) {
			error("Unable to construct config string: %d\n", curr_len);
			return;
		}

		len = snprintf(&buff[curr_len], BUFFER_SIZE - curr_len, "%u ", args->ignored_irqs[i]);
		if (len < 0 || len >= (int32_t) (BUFFER_SIZE - curr_len)) {
			error("Unable to construct config string: %d\n", len);
			return;
		}
		curr_len += len;
	}

	info("%s\n", buff);

}

static int32_t init_once(struct cmdline *args)
{
	uint32_t i;
	int32_t ret = 0;
	uint32_t max = sizeof(IRQ_IGNORE_LIST_DEF)/sizeof(IRQ_IGNORE_LIST_DEF[0]);

	args->rate_hz = DEF_RATE_HZ;
	args->decay_factor = DEF_DECAY_FACTOR;
	args->balancing_factor = DEF_BALANCING_FACTOR;
	args->cfg_file = NULL;

	max_cpus = sysconf(_SC_NPROCESSORS_CONF);

	/* Sanity check */
	if (max_cpus > MAX_CPUS_POSSIBLE) {
		error("Exiting... System reports %u CPUs available. This does not look right.\n",
			max_cpus);
		ret = -EINVAL;
		goto out;
	}

	args->cpu_prio = malloc(max_cpus * sizeof(*args->cpu_prio));
	if (!args->cpu_prio) {
		error("Out of memory. Unable to allocate cpu_prio\n");
		ret = -ENOMEM;
		goto out;
	}

	for (i = 0; i < max_cpus; ++i)
		args->cpu_prio[i] = 1;

	scratch_buffer = malloc(SCRATCH_BUF_LEN);
	if (!scratch_buffer) {
		error("Out of memory. Unable to allocate scratch buffer\n");
		ret = -ENOMEM;
		goto free_cpu_prio;
	}

	cpu_data = malloc(max_cpus * sizeof(*cpu_data));
	if (!cpu_data) {
		error("Out of memory. Unable to allocate cpu_data\n");
		ret = -ENOMEM;
		goto free_scratch;
	}

	cpu_active_list = malloc(max_cpus * sizeof(*cpu_active_list));
	if (!cpu_active_list) {
		error("Out of memory. Unable to allocate cpu_active_list\n");
		ret = -ENOMEM;
		goto free_cpu_data;
	}

	args->no_ignored_irqs = 0;
	for (i = 0; i < max && i < MAX_IGNORE_LIST_LEN; ++i)
		args->ignored_irqs[args->no_ignored_irqs++] = IRQ_IGNORE_LIST_DEF[i];

	debug_enabled = false;
	goto out;

free_cpu_data:
	free(cpu_data);
	cpu_data = NULL;
free_scratch:
	free(scratch_buffer);
	scratch_buffer = NULL;
free_cpu_prio:
	free(args->cpu_prio);
	args->cpu_prio = NULL;
out:
	return ret;
}

static void deinit_once(struct cmdline *args)
{
	free(cpu_active_list);
	free(cpu_data);
	free(scratch_buffer);
	free(args->cpu_prio);
	free(args->cfg_file);
}

static int32_t drop_root()
{
	int32_t ret;
	struct __user_cap_header_struct cap_header;
	struct __user_cap_data_struct cap_data;
	gid_t gid[1];

	memset(&cap_header, 0, sizeof(cap_header));

	ret = prctl(PR_SET_KEEPCAPS, 1, 0, 0, 0);
	if (ret < 0) {
		error("Failed ot set keepcaps: %s\n", strerror(errno));
		return ret;
	}

	ret = setgid(AID_NOBODY);
	if (ret < 0) {
		error("Unable to drop to group nobody from root: %s\n", strerror(errno));
		return ret;
	}

	gid[0] = AID_NOBODY;
	ret = setgroups(1, gid);
	if (ret < 0) {
		error("Unable to set supplemental groups: %s\n", strerror(errno));
		return ret;
	}

	ret = setuid(AID_NOBODY);
	if (ret < 0) {
		error("Unable to drop to user nobody from root: %s\n", strerror(errno));
		return ret;
	}

	cap_header.version = _LINUX_CAPABILITY_VERSION;
	ret = capget(&cap_header, &cap_data);
	if (ret < 0) {
		error("Failed to get capabilities: %s\n", strerror(errno));
		return ret;
	}

	/*
	 * Set only cap to access file system
	 */
	cap_data.inheritable = 0;
	cap_data.permitted = CAP_TO_MASK(CAP_DAC_OVERRIDE);
	cap_data.effective = cap_data.permitted;

	ret = capset(&cap_header, &cap_data);
	if (ret) {
		error("Failed to set capability: %s\n", strerror(errno));
		return ret;
	}

	ret = prctl(PR_SET_KEEPCAPS, 0, 0, 0, 0);
	if (ret < 0)
		error("Failed ot set keepcaps: %s\n", strerror(errno));

	return ret;
}

int main(int argc, char *argv[])
{
	struct cmdline cmdargs;
	int32_t ret;

	ret = drop_root();
	if (ret < 0)
		return ret;

	ret = init_once(&cmdargs);
	if (ret < 0)
		return ret;

	if (parse_cmdline(argc, argv, &cmdargs)) {
		ret = -1;
		goto deinit;
	}

	if (cmdargs.cfg_file) {
		ret = parse_cfg_file(&cmdargs);
		if (ret)
			goto deinit;
	}

	signal(SIGHUP, sig_handler);
	signal(SIGTERM, sig_handler);

	ret = run(&cmdargs);

deinit:
	deinit_once(&cmdargs);

	return ret;
}

